@inproceedings{guhr-EtAl:2021:fullstop,
  title     = {FullStop: Multilingual Deep Models for Punctuation Prediction},
  author    = {Guhr, Oliver and Schumann, Anne-Kathrin and Bahrmann, Frank and B\"{o}hme, Hans Joachim},
  booktitle = {Proceedings of the Swiss Text Analytics Conference 2021},
  month     = jun,
  year      = {2021},
  address   = {Winterthur, Switzerland},
  publisher = {CEUR Workshop Proceedings}
}


@article{barbero2024transformers,
  title   = {Transformers need glasses! Information over-squashing in language tasks},
  author  = {Barbero, Federico and Banino, Andrea and Kapturowski, Steven and Kumaran, Dharshan and Ara{\'u}jo, Jo{\~a}o GM and Vitvitskyi, Alex and Pascanu, Razvan and Veli{\v{c}}kovi{\'c}, Petar},
  journal = {arXiv preprint arXiv:2406.04267},
  year    = {2024}
}

@article{frohmann2024segment,
  title   = {Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation},
  author  = {Frohmann, Markus and Sterner, Igor and Vulic, Ivan and Minixhofer, Benjamin and Schedl, Markus},
  journal = {arXiv preprint arXiv:2406.16678},
  year    = {2024}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={4171--4186},
  year={2019}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={1--67},
  year={2020}
}

@article{liu2021self,
  title={Self-supervised learning: Generative or contrastive},
  author={Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={35},
  number={1},
  pages={677--694},
  year={2021}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{openai2023gpt4,
  title={GPT-4 Technical Report},
  author={{OpenAI}},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{sennrich2016neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics},
  pages={1715--1725},
  year={2016}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{wang2023self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2023}
}

@article{yao2023react,
  title={ReAct: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2023}
}

@article{lu2022fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2022}
}

@article{white2023prompt,
  title={Prompt engineering for large language models: A survey},
  author={White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C},
  journal={arXiv preprint arXiv:2307.10169},
  year={2023}
}

@article{kasneci2023chatgpt,
  title={ChatGPT for good? On opportunities and challenges of large language models for education},
  author={Kasneci, Enkelejda and Sessler, Kathrin and Küchemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and Gasser, Urs and Groh, Georg and Günnemann, Stephan and Hüllermeier, Eyke and others},
  journal={Learning and Individual Differences},
  volume={103},
  pages={102274},
  year={2023}
}

@article{liu2023lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Bosselut, Antoine and Srinivasan, Dora and Choi, Yejin and Hajishirzi, Hannaneh and Khashabi, Daniel},
  journal={arXiv preprint arXiv:2307.03172},
  year={2023}
}

@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jiang, Kangning and Shen, Jiawei and Ren, Xiang and Han, Jiawei},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}

@inproceedings{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  booktitle={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{xu2023retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Xu, Yuchen and Sarthi, Sanjay and Agarwal, Abhishek and Gupta, Abhirut and Saxena, Abhinav and Aralikatte, Rahul and Batra, Dzmitry and Parikh, Devi and Misra, Ishan and Awadallah, Ahmed},
  journal={arXiv preprint arXiv:2305.14002},
  year={2023}
}

@misc{openai2023pricing,
  title={Pricing},
  author={{OpenAI}},
  howpublished={\url{https://openai.com/pricing}},
  year={2023},
  note={Accessed: 2023-12-01}
}

@article{freeman2014active,
  title={Active learning increases student performance in science, engineering, and mathematics},
  author={Freeman, Scott and Eddy, Sarah L and McDonough, Miles and Smith, Michelle K and Okoroafor, Nnadozie and Jordt, Hannah and Wenderoth, Mary Pat},
  journal={Proceedings of the National Academy of Sciences},
  volume={111},
  number={23},
  pages={8410--8415},
  year={2014}
}

@book{bonwell1991active,
  title={Active Learning: Creating Excitement in the Classroom},
  author={Bonwell, Charles C and Eison, James A},
  year={1991},
  publisher={ASHE-ERIC Higher Education Report}
}

@article{prince2004does,
  title={Does active learning work? A review of the research},
  author={Prince, Michael},
  journal={Journal of Engineering Education},
  volume={93},
  number={3},
  pages={223--231},
  year={2004}
}

@article{dunlosky2013improving,
  title={Improving students' learning with effective learning techniques: Promising directions from cognitive and educational psychology},
  author={Dunlosky, John and Rawson, Katherine A and Marsh, Elizabeth J and Nathan, Mitchell J and Willingham, Daniel T},
  journal={Psychological Science in the Public Interest},
  volume={14},
  number={1},
  pages={4--58},
  year={2013}
}

@article{guo2014video,
  title={How video production affects student engagement: An empirical study of MOOC videos},
  author={Guo, Philip J and Kim, Juho and Rubin, Rob},
  journal={Proceedings of the first ACM conference on Learning@ scale conference},
  pages={41--50},
  year={2014}
}

@article{ibrahim2012effects,
  title={The effects of video-based and activity-based instructions on high school students' achievement, attitudes and metacognition in learning acid-base},
  author={Ibrahim, Mohamed and Callaway, Rebecca and Bell, David},
  journal={Journal of Science Education and Technology},
  volume={21},
  number={6},
  pages={720--728},
  year={2012}
}

@article{schwan2004learning,
  title={Learning by viewing versus learning by doing: Evidence-based guidelines for principled learning environments},
  author={Schwan, Stephan and Riempp, Roland},
  journal={Learning and Instruction},
  volume={14},
  number={6},
  pages={587--596},
  year={2004}
}

@article{mayer2019taking,
  title={Taking a new look at seductive details effects in multimedia learning},
  author={Mayer, Richard E and Fiorella, Logan},
  journal={Contemporary Educational Psychology},
  volume={56},
  pages={1--10},
  year={2019}
}

@article{szpunar2013interpolated,
  title={Interpolated memory tests reduce mind wandering and improve learning of online lectures},
  author={Szpunar, Karl K and Khan, Novall Y and Schacter, Daniel L},
  journal={Proceedings of the National Academy of Sciences},
  volume={110},
  number={16},
  pages={6313--6317},
  year={2013}
}

@article{chi2014learning,
  title={Learning from observing hands-on others learning},
  author={Chi, Michelene TH and Roy, Marguerite and Hausmann, Robert GM},
  journal={Cognitive Science},
  volume={38},
  number={2},
  pages={322--352},
  year={2014}
}

@article{liao2018impact,
  title={The impact of interactive video on students' learning in the undergraduate classroom},
  author={Liao, Yuen-Kuang Cliff and Chen, Yi-Wen and Chiang, Huei-Yin and Chang, Yuwen and Liu, Chun-Chi},
  journal={Journal of Educational Computing Research},
  volume={56},
  number={7},
  pages={1040--1059},
  year={2018}
}

@article{fiorella2020learning,
  title={Learning as a generative activity: Eight learning strategies that promote understanding},
  author={Fiorella, Logan and Mayer, Richard E},
  journal={Cambridge University Press},
  year={2020}
}



@article{karpicke2011retrieval,
  title={Retrieval practice produces more learning than elaborative studying with concept mapping},
  author={Karpicke, Jeffrey D and Blunt, Janell R},
  journal={Science},
  volume={331},
  number={6018},
  pages={772--775},
  year={2011}
}

@article{chi2001learning,
  title={Learning from human tutoring},
  author={Chi, Michelene TH and Siler, Stephanie A and Jeong, Heisawn and Yamauchi, Takashi and Hausmann, Robert G},
  journal={Cognitive Science},
  volume={25},
  number={4},
  pages={471--533},
  year={2001}
}

@article{chi2014icap,
  title={The ICAP framework: Linking cognitive engagement to active learning outcomes},
  author={Chi, Michelene TH and Wylie, Ruth},
  journal={Educational Psychologist},
  volume={49},
  number={4},
  pages={219--243},
  year={2014}
}

@article{sweller2011cognitive,
  title={Cognitive load theory, evolutionary educational psychology, and instructional design},
  author={Sweller, John},
  journal={Evolutionary Psychology and Information Systems Research},
  pages={270--302},
  year={2011}
}

@article{roediger2006power,
  title={The power of testing memory: Basic research and implications for educational practice},
  author={Roediger III, Henry L and Karpicke, Jeffrey D},
  journal={Perspectives on Psychological Science},
  volume={1},
  number={3},
  pages={181--210},
  year={2006}
}

@article{bransford1999rethinking,
  title={Rethinking transfer: A simple proposal with multiple implications},
  author={Bransford, John D and Schwartz, Daniel L},
  journal={Review of Research in Education},
  volume={24},
  number={1},
  pages={61--100},
  year={1999}
}


@article{bommasani2021opportunities,
  title   = {On the opportunities and risks of foundation models},
  author  = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal = {arXiv preprint arXiv:2108.07258},
  year    = {2021}
}

@article{liu2023evaluating,
  title   = {Evaluating large language models: A comprehensive survey},
  author  = {Liu, Yang and Sun, Yuansheng and Zhong, Yangyi and Han, Chiyu and Sun, Ruixiang and Zhang, Xiao and Peng, Yuxiao and Tang, Zhengyuan and Huang, Jiaqi and Lai, Zhongyu and others},
  journal = {arXiv preprint arXiv:2310.19736},
  year    = {2023}
}

@article{vemprala2023chatgpt,
  title   = {ChatGPT for robotics: Design principles and model abilities},
  author  = {Vemprala, Sai and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},
  journal = {arXiv preprint arXiv:2306.17582},
  year    = {2023}
}

@article{mialon2023augmented,
  title   = {Augmented language models: a survey},
  author  = {Mialon, Gr{\'e}goire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
  journal = {arXiv preprint arXiv:2302.07842},
  year    = {2023}
}

@article{zheng2023judging,
  title   = {Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  author  = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Gonzalez, Joseph and others},
  journal = {arXiv preprint arXiv:2306.05685},
  year    = {2023}
}

@article{weng2023llm,
  title   = {LLM powered autonomous agents},
  author  = {Weng, Lilian},
  journal = {lilianweng.github.io},
  year    = {2023}
}


@article{singh2025agentic,
  title   = {Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG},
  author  = {Singh, Aditi and Ehtesham, Abul and Kumar, Saket and Khoei, Tala Talaei},
  journal = {arXiv preprint arXiv:2501.09136},
  year    = {2025}
}